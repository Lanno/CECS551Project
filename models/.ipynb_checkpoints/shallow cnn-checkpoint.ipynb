{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, MaxPooling1D, UpSampling1D\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "import medleydb as mdb\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "multitracks = mdb.load_multitracks([\"Phoenix_ColliersDaughter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix = next(multitracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate, mix_audio = wavfile.read(mix.mix_path)\n",
    "mix_audio = mix_audio.mean(1)\n",
    "mix_audio = mix_audio[sample_rate*8:int(-sample_rate*1.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_period = 256\n",
    "overlap = int(samples_per_period/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-283-7743a0115cc1>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-283-7743a0115cc1>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    noverlap=overlap, nperseg=samples_per_period)\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "freqs, times, s_mix = signal.stft(mix_audio, fs=sample_rate, nfft=samples_per_period, return_onesided=False,\n",
    "                                         noverlap=overlap, nperseg=samples_per_period)\n",
    "\n",
    "freqs = freqs[:-1]\n",
    "s_mix = s_mix[:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(times, freqs, 20*np.log10(np.abs(s_mix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Flute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flutes = mdb.get_files_for_instrument(\"flute\", [mix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flute = next(flutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate, flute_audio = wavfile.read(flute)\n",
    "flute_audio = flute_audio.mean(1)\n",
    "flute_audio = flute_audio[sample_rate*8:int(-sample_rate*1.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs, times, s_flute = signal.stft(flute_audio, fs=sample_rate, nfft=samples_per_period, return_onesided=False,\n",
    "                                           noverlap=overlap, nperseg=samples_per_period)\n",
    "\n",
    "freqs = freqs[:-1]\n",
    "s_flute = s_flute[:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(times, freqs, 20*np.log10(np.abs(s_flute)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a mask for the flute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_flute = s_flute / (s_flute + s_mix + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(times, freqs, 20*np.log10(np.abs(mask_flute)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s_mix_train = s_mix.reshape(*s_mix.T.shape, 1)\n",
    "#s_mix_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test  = int((sample_rate * 10)/samples_per_period)\n",
    "num_train = s_mix.shape[1] - num_test\n",
    "print(num_train, num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_train = s_mix.T[:num_train,:,np.newaxis]\n",
    "mix_train = np.concatenate((mix_train.real, mix_train.imag), axis=-1)\n",
    "mix_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flute_train = mask_flute.T[:num_train,:,np.newaxis]\n",
    "flute_train = np.concatenate((flute_train.real, flute_train.imag), axis=-1)\n",
    "flute_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_test = s_mix.T[-num_test:,:,np.newaxis]\n",
    "mix_test = np.concatenate((mix_test.real, mix_test.imag), axis=-1)\n",
    "mix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flute_test = mask_flute.T[-num_test:,:,np.newaxis]\n",
    "flute_test = np.concatenate((flute_test.real, flute_test.imag), axis=-1)\n",
    "flute_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(10, 2, padding=\"same\", input_shape=mix_train.shape[1:], activation=\"relu\", name=\"Conv1D_1\"))\n",
    "\n",
    "model.add(Conv1D(2, 2, padding=\"same\",  name=\"Conv1D_2\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(mix_train, flute_train, batch_size=200, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(mix_test, flute_test)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_prediction = model.predict(mix_test)\n",
    "mask_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_prediction = np.sqrt((mask_prediction**2).sum(-1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3,sharey=True,figsize=(12, 4))\n",
    "\n",
    "ax1.set_title(\"Input Mixture\")\n",
    "ax2.set_title(\"Target Flute Mask\")\n",
    "ax3.set_title(\"Generated Flute Mask\")\n",
    "\n",
    "ax1.pcolormesh(times[-num_test:], freqs, 20*np.log10(np.abs(s_mix[:,-num_test:])))\n",
    "ax2.pcolormesh(times[-num_test:], freqs, 20*np.log10(np.abs(mask_flute[:,-num_test:])))\n",
    "ax3.pcolormesh(times[-num_test:], freqs, 20*np.log10(mask_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = s_mix[:,-num_test:] * mask_flute[:,-num_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = s_mix[:,-num_test:] * mask_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(12, 4))\n",
    "\n",
    "ax1.set_title(\"Input Mixture\")\n",
    "ax2.set_title(\"Target\")\n",
    "ax3.set_title(\"Prediction\")\n",
    "\n",
    "ax1.pcolormesh(times[-num_test:], freqs, 20*np.log10(np.abs(s_mix[:,-num_test:])))\n",
    "ax2.pcolormesh(times[-num_test:], freqs, 20*np.log10(np.abs(target)))\n",
    "ax3.pcolormesh(times[-num_test:], freqs, 20*np.log10(np.abs(prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's hear it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted_audio = signal.istft(prediction, fs=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfile.write(\"basic_model_flute_prediction.wav\", sample_rate, predicted_audio.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, target_audio = signal.istft(target, fs=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfile.write(\"basic_model_flute_target.wav\", sample_rate, target_audio.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, mix_audio = signal.istft(s_mix[:,-num_test:], fs=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfile.write(\"basic_model_original.wav\", sample_rate, mix_audio.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
